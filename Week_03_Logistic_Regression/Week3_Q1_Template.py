# -*- coding: utf-8 -*-
"""Week3_Template_LR.ipynb
Automatically generated by Colaboratory.
# Logistic  Regression
Fill the blank spaces as required. 
Do not change name of any class, method name.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from scipy import optimize
import pandas as pd
from matplotlib import pyplot

class lr:
    # Data cleaning and finding the mean of the column titled "MaxTemp"
    def data_clean(self,data):
        # 'data' is a dataframe imported from '.csv' file using 'pandas'
        # Perform data cleaning steps sequentially as mentioned in assignment
        
        
        
        X =             # X (Feature matrix) - should be numpy array
        y =             # y (prediction vector) - should be numpy arrays
        mean =          # Mean of a the normalized "MaxTemp" column rounded off to 3 decimal places
    
        return X, y, mean

class costing:
    # define the function needed to evaluate cost function
    # Input 'z' could be a scalar or a 1D vector
    def sigmoid(self,z):
        
        
        
        return g
    
    # Regularized cost function definition
    def costFunctionReg(self,w,X,y,lambda_):
        
        
        
        J =             # Cost 'J' should be a scalar
        grad =          # Gradient 'grad' should be a vector
        
        return J, grad
    
    # Prediction based on trained model
    # Use sigmoid function to calculate probability rounded off to either 0 or 1
    def predict(self,w,X):
        
        
        
        
        p =             # 'p' should be a vector of size equal to that of vector 'y'
        
        return p
    
    # Optimization defintion
    def minCostFun(self, w_ini, X_train, y_train, iters):
        # iters - Maximum no. of iterations; X_train - Numpy array
        lambda_ =       # Regularization parameter
        X_train =       # Add '1' for bias term
        
        
        
        
        w_opt =         # Optimized weights rounded off to 3 decimal places
        
        acrcy =         # Training set accuracy (in %) rounded off to 3 decimal places
        
        return w_opt, acrcy
    
    # Calculate testing accuracy
    def TestingAccu(self, w_opt, X_test, y_test):
        w_opt =         # Optimum weights calculated using training data
        X_test =        # Add '1' for bias term
        
        
        
        acrcy_test =    # Testing set accuracy (in %) rounded off to 3 decimal places
        
        return acrcy_test