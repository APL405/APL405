{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hldO983whghc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4Lz82ENhlIN"
   },
   "outputs": [],
   "source": [
    "class mr:\n",
    "  # Evaluates the gradient of cost function (J). Hint: You can use this to optimize w\n",
    "  def grad(self,x,y,w):\n",
    "    m = y.size\n",
    "    grad_J = (1/m)*np.dot((np.dot(x,w) - y),x)\n",
    "    return grad_J\n",
    "\n",
    "  # This function calculates the cost (J)\n",
    "  def computeCost(self,x,y,w):\n",
    "    J = 0    # J is cost function\n",
    "    m = y.size\n",
    "    J = (1/(2*m))*np.sum(np.square(np.matmul(x,w) - y)) # write your code to calculate J\n",
    "    return J\n",
    "  \n",
    "  # This function optimizes the weights w_0, w_1, w_2. Batch Gradient Descent method\n",
    "  def bgdMulti(self, x, y, w, alpha, iters):\n",
    "    m = y.size  # number of training examples\n",
    "    w = w.copy() # To keep a copy of original weights\n",
    "    \n",
    "    J_history = []   # Use a python list to save cost in every iteration\n",
    "\n",
    "    for i in range(iters):\n",
    "      # Loop to update weights (w vector)\n",
    "      # Also save cost at every step\n",
    "      w = w - (alpha)*self.grad(x,y,w);\n",
    "      J_history.append(self.computeCost(x, y, w))\n",
    "        \n",
    "    self.w = w\n",
    "    return w, J_history\n",
    "  \n",
    "  # Estimate the price of a 4 bedrooms, 2.5 bathrooms, 2570 sq. feet area, 2 floors, 2005 yr. built\n",
    "  # You need to rescale all the values, mu is mean of all X data of each column, sigma is standard deviation of X data. mu , sigma will be vector\n",
    "  # You need to do feature normalization of all x (see lab notes)\n",
    "  def predict(self, mu, sigma):\n",
    "    price = 0\n",
    "    x = np.array([4,2.5,2570,2,2005])\n",
    "    x = (x-mu)/sigma\n",
    "    x = np.hstack((np.ones(1),x))\n",
    "    price = np.matmul(x , self.w)\n",
    "    error = (abs(719000 - price)/719000)*100\n",
    "    \n",
    "    # This is another way. this will run if you hardcode w\n",
    "    #price =  w[0] + w[1]*((4 -mu[0])/sigma[0]) + w[2]*((2.5 -mu[1])/sigma[1]) + w[3]*((2570 -mu[2])/sigma[2]) + w[4]*((2 -mu[3])/sigma[3]) +w[5]*((2005 -mu[4])/sigma[4]) # predict the price of the house\n",
    "    \n",
    "    return price, error"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week2_Q2_Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
